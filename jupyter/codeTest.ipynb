{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 文本分类步骤\n",
    "- 划分数据集\n",
    "- 对标题和正文分词和去停用词\n",
    "- 计算tf-idf等特征\n",
    "- 构建分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从ES取出带标签的数据，分词，并dump到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功导出新闻数据：size=103320\n",
      "完成对新闻标题的分词\n",
      "成功将分词后的数据dump到本地\n",
      "成功dump训练集到本地：size=82656\n",
      "成功dump测试集到本地：size=20664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'doc_title': ['下水道', '替代', '方案', '蓄洪', '池', '密码'], 'doc_type': '财经'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import esProxy\n",
    "from analyzer import Analyzer\n",
    "import pickle, random\n",
    "\n",
    "# 从ES导出带标签的新闻数据\n",
    "sougouNews = esProxy.getDataFromEs()\n",
    "print('成功导出新闻数据：size=%d' % (len(sougouNews)))\n",
    "\n",
    "def featurelize(sougouNews, fields=['doc_title'], analyzer=Analyzer()):\n",
    "    \"\"\"\n",
    "    返回标签和分词后的特征\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for doc in sougouNews:\n",
    "        dic = {}\n",
    "        for field in fields:\n",
    "            dic[field] = analyzer.cutAndFilter(doc[field])\n",
    "        # 添加新闻类别\n",
    "        dic['doc_type'] = doc['doc_type']\n",
    "        tokens.append(dic)\n",
    "    return tokens\n",
    "\n",
    "# 对新闻标题进行分词，得到带分词的新闻数据\n",
    "tokenSougouNews = featurelize(sougouNews, fields=['doc_title'], analyzer=Analyzer())\n",
    "print('完成对新闻标题的分词')\n",
    "\n",
    "# 将分词后的结果dump到本地\n",
    "with open('tokenSougouNews.pk', 'wb') as f:\n",
    "    f.truncate()\n",
    "    pickle.dump(tokenSougouNews, f)\n",
    "print('成功将分词后的数据dump到本地')\n",
    "\n",
    "# 划分训练集和测试集\n",
    "random.shuffle(tokenSougouNews)\n",
    "trainPercent = 0.8\n",
    "# dump训练集\n",
    "with open('tokenSougouNews-train.pk', 'wb') as f:\n",
    "    f.truncate()\n",
    "    pickle.dump(tokenSougouNews[:int(trainPercent*len(tokenSougouNews))], f)\n",
    "print('成功dump训练集到本地：size=%d' % (int(trainPercent*len(tokenSougouNews))))\n",
    "    \n",
    "# dump测试集\n",
    "with open('tokenSougouNews-test.pk', 'wb') as f:\n",
    "    f.truncate()\n",
    "    pickle.dump(tokenSougouNews[int(trainPercent*len(tokenSougouNews)):], f)\n",
    "print('成功dump测试集到本地：size=%d' % (len(tokenSougouNews) - int(trainPercent*len(tokenSougouNews))))\n",
    "\n",
    "tokenSougouNews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "\n",
    "X = [1,2,3,4]\n",
    "random.shuffle(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
